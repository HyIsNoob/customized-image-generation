{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Textual Inversion Style Transfer Test - Kaggle\n",
        "\n",
        "Test style transfer từ ảnh COCO với Textual Inversion embedding đã train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"WARNING: No GPU detected!\")\n",
        "else:\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "import torch\n",
        "\n",
        "os.environ[\"XFORMERS_DISABLED\"] = \"1\"\n",
        "\n",
        "try:\n",
        "    import xformers\n",
        "    USE_XFORMERS = True\n",
        "except:\n",
        "    USE_XFORMERS = False\n",
        "\n",
        "PLACEHOLDER_TOKEN = \"<sks_style>\"\n",
        "MIXED_PRECISION = \"fp16\"\n",
        "STRENGTH = 0.5\n",
        "GUIDANCE = 7.5\n",
        "\n",
        "TI_EMBEDDING_PATHS = {\n",
        "    \"sks_style\": \"/kaggle/input/your-ti-dataset/sks_style_embeddings/sks_style_embedding_fp32.pt\",\n",
        "}\n",
        "\n",
        "COCO_IMAGE_PATHS = [\n",
        "    \"/kaggle/input/coco-2017-dataset/coco2017/val2017\",\n",
        "    \"/kaggle/input/coco2017/val2017\",\n",
        "]\n",
        "\n",
        "for style_name, embedding_path in TI_EMBEDDING_PATHS.items():\n",
        "    if os.path.exists(embedding_path):\n",
        "        print(f\"{style_name}: {embedding_path}\")\n",
        "    else:\n",
        "        print(f\"{style_name}: {embedding_path} (not found)\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"/kaggle/working/ti_inference_samples\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coco_image_dir = None\n",
        "for path in COCO_IMAGE_PATHS:\n",
        "    if os.path.exists(path):\n",
        "        coco_image_dir = Path(path)\n",
        "        print(f\"Found COCO images: {coco_image_dir}\")\n",
        "        break\n",
        "\n",
        "if coco_image_dir is None:\n",
        "    print(\"COCO dataset not found\")\n",
        "    coco_image_dir = Path(\"/kaggle/input/coco2017/val2017\")\n",
        "\n",
        "image_files = list(coco_image_dir.glob(\"*.jpg\"))[:5]\n",
        "if len(image_files) == 0:\n",
        "    image_files = list(coco_image_dir.glob(\"*.png\"))[:5]\n",
        "\n",
        "print(f\"Found {len(image_files)} images\")\n",
        "for img_path in image_files:\n",
        "    print(f\"  {img_path.name}\")\n",
        "\n",
        "coco_images = []\n",
        "for img_path in image_files:\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img = img.resize((512, 512))\n",
        "    coco_images.append(img)\n",
        "    print(f\"Loaded: {img_path.name} ({img.size})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading baseline model...\")\n",
        "baseline_pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16 if MIXED_PRECISION == \"fp16\" else torch.float32,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False,\n",
        ")\n",
        "if torch.cuda.is_available():\n",
        "    baseline_pipeline = baseline_pipeline.to(\"cuda\")\n",
        "    if not USE_XFORMERS:\n",
        "        baseline_pipeline.enable_attention_slicing()\n",
        "print(\"Baseline model loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_textual_inversion_embedding(pipeline, embedding_path, placeholder_token):\n",
        "    embedding_data = torch.load(embedding_path, map_location=\"cpu\")\n",
        "    \n",
        "    if isinstance(embedding_data, dict):\n",
        "        embedding = embedding_data[\"embedding\"]\n",
        "        token = embedding_data.get(\"placeholder_token\", placeholder_token)\n",
        "    else:\n",
        "        embedding = embedding_data\n",
        "        token = placeholder_token\n",
        "    \n",
        "    tokenizer = pipeline.tokenizer\n",
        "    text_encoder = pipeline.text_encoder\n",
        "    \n",
        "    num_added = tokenizer.add_tokens(token)\n",
        "    if num_added == 0:\n",
        "        print(f\"Token {token} already exists\")\n",
        "    \n",
        "    placeholder_token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "    \n",
        "    text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "    embedding_layer = text_encoder.get_input_embeddings()\n",
        "    \n",
        "    if embedding.dim() == 1:\n",
        "        embedding = embedding.unsqueeze(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        embedding_layer.weight[placeholder_token_id] = embedding.squeeze(0).to(\n",
        "            embedding_layer.weight.dtype\n",
        "        )\n",
        "    \n",
        "    print(f\"Loaded embedding for token: {token}\")\n",
        "    return token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading Textual Inversion models...\")\n",
        "ti_pipelines = {}\n",
        "\n",
        "for style_name, embedding_path in TI_EMBEDDING_PATHS.items():\n",
        "    if not os.path.exists(embedding_path):\n",
        "        print(f\"Embedding not found: {embedding_path}\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\nLoading {style_name} from {embedding_path}...\")\n",
        "    try:\n",
        "        pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "            \"runwayml/stable-diffusion-v1-5\",\n",
        "            torch_dtype=torch.float16 if MIXED_PRECISION == \"fp16\" else torch.float32,\n",
        "            safety_checker=None,\n",
        "            requires_safety_checker=False,\n",
        "        )\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            pipeline = pipeline.to(\"cuda\")\n",
        "            if not USE_XFORMERS:\n",
        "                pipeline.enable_attention_slicing()\n",
        "        \n",
        "        token = load_textual_inversion_embedding(pipeline, embedding_path, PLACEHOLDER_TOKEN)\n",
        "        ti_pipelines[style_name] = {\"pipeline\": pipeline, \"token\": token}\n",
        "        print(f\"{style_name} loaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {style_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating baseline results...\")\n",
        "baseline_results = []\n",
        "baseline_prompt = \"a painting\"\n",
        "\n",
        "for i, coco_img in enumerate(coco_images):\n",
        "    print(f\"  Baseline {i+1}/{len(coco_images)}\")\n",
        "    result = baseline_pipeline(\n",
        "        prompt=baseline_prompt,\n",
        "        image=coco_img,\n",
        "        strength=STRENGTH,\n",
        "        num_inference_steps=50,\n",
        "        guidance_scale=GUIDANCE,\n",
        "    ).images[0]\n",
        "    baseline_results.append(result)\n",
        "    result.save(OUTPUT_DIR / f\"baseline_transfer_{i+1}.png\")\n",
        "\n",
        "print(f\"Saved {len(baseline_results)} baseline transfers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_results = {}\n",
        "\n",
        "for style_name, style_data in ti_pipelines.items():\n",
        "    pipeline = style_data[\"pipeline\"]\n",
        "    token = style_data[\"token\"]\n",
        "    \n",
        "    print(f\"\\nTransferring {style_name}...\")\n",
        "    style_results = []\n",
        "    style_prompt = f\"a painting in {token} style\"\n",
        "    \n",
        "    for i, coco_img in enumerate(coco_images):\n",
        "        print(f\"  Image {i+1}/{len(coco_images)}\")\n",
        "        result = pipeline(\n",
        "            prompt=style_prompt,\n",
        "            image=coco_img,\n",
        "            strength=STRENGTH,\n",
        "            num_inference_steps=50,\n",
        "            guidance_scale=GUIDANCE,\n",
        "        ).images[0]\n",
        "        style_results.append(result)\n",
        "        result.save(OUTPUT_DIR / f\"{style_name}_transfer_{i+1}.png\")\n",
        "    \n",
        "    all_results[style_name] = style_results\n",
        "    print(f\"Saved {len(style_results)} transfers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_images = len(coco_images)\n",
        "num_styles = len(all_results)\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "    num_styles + 2,\n",
        "    num_images,\n",
        "    figsize=(4 * num_images, 4 * (num_styles + 2))\n",
        ")\n",
        "\n",
        "for col in range(num_images):\n",
        "    axes[0, col].imshow(coco_images[col])\n",
        "    axes[0, col].set_title(f\"Original\\n{col+1}\", fontsize=9)\n",
        "    axes[0, col].axis('off')\n",
        "    \n",
        "    axes[1, col].imshow(baseline_results[col])\n",
        "    axes[1, col].set_title(f\"Baseline\\n{col+1}\", fontsize=9)\n",
        "    axes[1, col].axis('off')\n",
        "\n",
        "for row, style_name in enumerate(all_results.keys(), 2):\n",
        "    for col in range(num_images):\n",
        "        axes[row, col].imshow(all_results[style_name][col])\n",
        "        axes[row, col].set_title(f\"{style_name}\\n{col+1}\", fontsize=9)\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"style_transfer_comparison.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Saved: {OUTPUT_DIR / 'style_transfer_comparison.png'}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
